import json
from collections import defaultdict
from typing import List, Dict, Tuple, Optional
from pathlib import Path


class GraphGenerator:
    """ì–´ë…¸í…Œì´ì…˜ì„ ê·¸ë˜í”„ í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤ (latex_class.json ì‚¬ìš©)"""
    
    def __init__(self, latex_data):
        """
        Args:
            latex_data: ìˆ˜ì‹ ê´€ê³„ ë°ì´í„° (latex_class.jsonì„ json.load í•œ dict)
        """
        # symbol2id ë§¤í•‘ ë¡œë“œ
        symbols = latex_data["symbols"]
        self.symbol_to_id = symbols.get('symbol2id', {})
        self.id_to_symbol = symbols.get('id2symbol', {})
        
        # ê´€ê³„ ì¹´í…Œê³ ë¦¬ ë¡œë“œ
        if "relations" not in latex_data:
            raise ValueError("JSON íŒŒì¼ì— 'relations' í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

        relations = latex_data['relations']
        
        # key â†’ int, value â†’ str
        self.rel_id_to_name = {int(k): v for k, v in relations.items()}
        # ì—­ë§¤í•‘: ê´€ê³„ëª… â†’ ID
        self.rel_to_id = {v: k for k, v in self.rel_id_to_name.items()}
    
    def parse_annotation_line(self, line: str) -> Tuple[Optional[str], Optional[List[str]]]:
        """
        ì–´ë…¸í…Œì´ì…˜ ë¼ì¸ì„ íŒŒì‹±í•©ë‹ˆë‹¤.
        
        ì…ë ¥ ì˜ˆì‹œ:
        "crohme2019/test/UN19_1032.inkml\t4 Right n Right - Right 4"
        
        Returns:
            (íŒŒì¼ëª…, í† í° ë¦¬ìŠ¤íŠ¸) ë˜ëŠ” (None, None)
        """
        parts = line.strip().split('\t')
        if len(parts) != 2:
            return None, None
        
        filename = parts[0]
        tokens = parts[1].split()
        
        return filename, tokens
    
    def tokens_to_graph(self, tokens: List[str]) -> Tuple[List[int], List[List[int]]]:
        """
        í† í° ì‹œí€€ìŠ¤ë¥¼ (ì‹¬ë³¼ ID ë¦¬ìŠ¤íŠ¸, ê´€ê³„ ë¦¬ìŠ¤íŠ¸)ë¡œ ë³€í™˜.
        
        - ì‹¬ë³¼ ID ë¦¬ìŠ¤íŠ¸: latex_class.jsonì˜ symbol2idì— ë”°ë¼ ë§¤í•‘ëœ ì •ìˆ˜ ID
        - ê´€ê³„ ë¦¬ìŠ¤íŠ¸: [from_node_idx, to_node_idx, rel_id] í˜•íƒœ
        
        node indexëŠ” "í† í° ì‹œí€€ìŠ¤ì—ì„œ ê´€ê³„ í† í°ì´ ì•„ë‹Œ ì‹¬ë³¼ì˜ ë“±ì¥ ìˆœì„œ"ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©.
        ì˜ˆë¥¼ ë“¤ì–´ í† í°ì´ [4, Right, n, Right, -] ë¼ë©´
        ì‹¬ë³¼ ì‹œí€€ìŠ¤ëŠ” [4, n, -] â†’ ë…¸ë“œ ì¸ë±ìŠ¤ [0, 1, 2]
        """

        # ğŸ‘‡ ì‹¬ë³¼ í† í° alias â†’ ì‹¤ì œ ê¸°í˜¸ë¡œ ë§¤í•‘ (COMMA ë“±)
        alias_map = {
            "COMMA": ",",
            # í•„ìš”í•˜ë©´ ë‚˜ì¤‘ì— "DOT": ".", "SPACE": r"\ " ê°™ì€ ê²ƒë„ ì¶”ê°€ ê°€ëŠ¥
        }
                
        symbol_tokens: List[str] = []
        token_pos_to_node_idx: Dict[int, int] = {}
        relations: List[List[int]] = []
        unknown_symbols = set()
        
        # 1-pass: ì‹¬ë³¼ í† í°ë§Œ ëª¨ìœ¼ê³ , í† í° ìœ„ì¹˜â†’ë…¸ë“œ ì¸ë±ìŠ¤ ë§¤í•‘
        node_idx = 0
        for i, tok in enumerate(tokens):
            if tok not in self.rel_to_id:  # ê´€ê³„ í‚¤ì›Œë“œê°€ ì•„ë‹ˆë©´ ì‹¬ë³¼
                token_pos_to_node_idx[i] = node_idx
                symbol_tokens.append(tok)
                node_idx += 1
        
        # 2-pass: ê´€ê³„ í† í°ì„ ë³´ë©´ì„œ ì•/ë’¤ ì‹¬ë³¼ì„ ì—£ì§€ë¡œ ì—°ê²°
        for i, tok in enumerate(tokens):
            if tok in self.rel_to_id:
                rel_name = tok
                if rel_name == "NoRel":
                    continue  # NoRelì€ ì—£ì§€ ë§Œë“¤ì§€ ì•ŠìŒ
                
                # ê´€ê³„ í† í° ì–‘ ì˜†ì— ì‹¬ë³¼ì´ ìˆëŠ” ê²½ìš°ë§Œ ì‚¬ìš©
                if (i - 1) in token_pos_to_node_idx and (i + 1) in token_pos_to_node_idx:
                    src_idx = token_pos_to_node_idx[i - 1]
                    dst_idx = token_pos_to_node_idx[i + 1]
                    rel_id = self.rel_to_id[rel_name]
                    relations.append([src_idx, dst_idx, rel_id])
        
        # ì‹¬ë³¼ í† í°ì„ IDë¡œ ë³€í™˜ (labels ì—­í• )
        symbol_ids: List[int] = []
        for tok in symbol_tokens:
            if tok in self.symbol_to_id:
                symbol_ids.append(self.symbol_to_id[tok])
            else:
                symbol_ids.append(-1)
                unknown_symbols.add(tok)
        
        if unknown_symbols:
            print(f"Warning: Unknown symbols found: {unknown_symbols}")
        
        return symbol_ids, relations
    
    def create_graph_from_file(self, 
                               annotation_file: str,
                               file_id: Optional[str] = None) -> Optional[Dict]:
        """
        ë‹¨ì¼ ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ì„ ì½ì–´ ê·¸ë˜í”„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Returns:
            {
                'labels': List[int],      # ë…¸ë“œë³„ ì‹¬ë³¼ í´ë˜ìŠ¤ ID
                'relations': List[List[int]],
                'filename': str,
                'file_id': str
            }
        """
        with open(annotation_file, 'r', encoding='utf-8') as f:
            line = f.readline()
        
        filename, tokens = self.parse_annotation_line(line)
        if filename is None or tokens is None:
            return None
        
        symbol_ids, relations = self.tokens_to_graph(tokens)
        
        if file_id is None:
            file_id = Path(filename).stem
        
        return {
            'labels': symbol_ids,
            'relations': relations,
            'filename': filename,
            'file_id': file_id
        }
    
    def create_graph_batch(self, 
                           annotation_file: str,
                           output_format: str = 'detailed') -> Dict:
        """
        ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ì˜ ëª¨ë“  í•­ëª©ì„ ê·¸ë˜í”„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        output_format:
            'simple'  â†’ file_id: [[src, dst, rel_id], ...]
            'detailed'â†’ file_id: {
                             'labels': [...],
                             'relations': [[src, dst, rel_id], ...],
                             'filename': str
                          }
        """
        result: Dict[str, Dict] = {}
        
        with open(annotation_file, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                filename, tokens = self.parse_annotation_line(line)
                if filename is None or tokens is None:
                    continue
                
                file_id = Path(filename).stem
                symbol_ids, relations = self.tokens_to_graph(tokens)
                
                if output_format == 'simple':
                    result[file_id] = relations
                else:
                    result[file_id] = {
                        'labels': symbol_ids,
                        'relations': relations,
                        'filename': filename
                    }
        
        return result
    
    def save_graph_json(self,
                        annotation_file: str,
                        output_file: str,
                        split_name: str = 'train',
                        output_format: str = 'detailed'):
        """
        ê·¸ë˜í”„ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        
        result (detailed ê¸°ì¤€):
        {
          "train": {
            "file_id": {
              "labels": [...],
              "relations": [[src, dst, rel_id], ...],
              "filename": "crohme2019/train/XXX.inkml"
            },
            ...
          },
          "rel_categories": { "Right": 1, ... },
          "num_classes": 320,
          "symbol_to_id": {...}
        }
        """
        graphs = self.create_graph_batch(annotation_file, output_format)
        
        result = {
            split_name: graphs,
            'rel_categories': self.rel_to_id,
            'num_classes': len(self.symbol_to_id),
            'symbol_to_id': self.symbol_to_id
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        
        print(f"ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ: {output_file}")
        print(f"  - ìƒ˜í”Œ ìˆ˜: {len(graphs)}")
        print(f"  - ê´€ê³„ ì¹´í…Œê³ ë¦¬: {len(self.rel_to_id)}ê°œ")
        print(f"  - ê¸°í˜¸ í´ë˜ìŠ¤: {len(self.symbol_to_id)}ê°œ")
