# data/formula/formula_graph_dataset.py

import json
import os
from typing import Any, Dict, List, Tuple, Union

import torch
from torch.utils.data import Dataset
from PIL import Image
import numpy as np


class FormulaGraphDataset(Dataset):
    """
    Crohme/HME ìˆ˜ì‹ ê·¸ë˜í”„ìš© Dataset.

    âœ… ì§€ì› JSON í¬ë§· 1 (dict):

    {
      "train": {
        "UN19_1032_em_455": {
          "filename": "crohme2019/train/UN19_1032_em_455.png",
          "boxes": [[x0,y0,x1,y1], ...],   # ë˜ëŠ” "bboxes"
          "labels": [class_id, ...],
          "relations": [[i,j,rel_id], ...],
          "latex": "\\frac{a+b}{c^2}"      # (ì˜µì…˜)
        },
        ...
      },

      "val": { ... },
      "test": { ... },

      "symbol_to_id": {...},
      "rel_categories": {...},
      "num_classes": 320
    }

    âœ… ì§€ì› JSON í¬ë§· 2 (list, EGTR formulaìš©):

    {
      "test": [
        {
          "filename": "DUMMY_001.inkml",  # ë˜ëŠ” "DUMMY_001"
          "bboxes": [[x0,y0,x1,y1], ...],
          "labels": [...],
          "relations": [[i,j,rel_id], ...]
        },
        ...
      ],
      "rel_categories": {...},
      "num_classes": 320,
      "symbol_to_id": {...}
    }

    â• train/valì´ ì—†ìœ¼ë©´ train/val ìš”ì²­ ì‹œ ìë™ìœ¼ë¡œ test splitì„ ëŒ€ì‹  ì‚¬ìš©.
    """

    def __init__(
        self,
        json_path: str,
        split: str,
        images_root: str,
        feature_extractor=None,
        transforms=None,
    ):
        super().__init__()
        assert split in ["train", "val", "test"], f"Unknown split: {split}"

        # -------------------------
        # 1. JSON ë¡œë“œ
        # -------------------------
        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        # splitì´ ì—†ìœ¼ë©´ testë¡œ fallback
        if split not in data:
            if "test" in data:
                print(
                    f"[FormulaGraphDataset] Split '{split}' not found in {json_path}. "
                    f"ëŒ€ì‹  'test' splitì„ ì‚¬ìš©í•©ë‹ˆë‹¤ (sanity check ìš©)."
                )
                split_data = data["test"]
            else:
                raise KeyError(
                    f"Split '{split}' not found in {json_path}. "
                    f"ì§€ê¸ˆ JSON ì•ˆì— '{split}' í‚¤ê°€ ì—†ëŠ” ê²ƒ ê°™ì•„. "
                    f"í˜„ì¬ êµ¬ì¡°ë¥¼ í•œë²ˆ í™•ì¸í•´ë´ì•¼ í•´."
                )
        else:
            split_data = data[split]

        # dict / list í˜•ì‹ ìë™ ê°ì§€
        if isinstance(split_data, dict):
            # {"id": {...}, ...}
            self.mode = "dict"
            self.graphs: Dict[str, Dict[str, Any]] = split_data
            self.ids: List[Union[str, int]] = list(self.graphs.keys())
        elif isinstance(split_data, list):
            # [{...}, {...}, ...]
            self.mode = "list"
            self.samples: List[Dict[str, Any]] = split_data
            self.ids = list(range(len(self.samples)))
        else:
            raise TypeError(
                f"Unsupported split data type: {type(split_data)} "
                f"(dict ë˜ëŠ” listë§Œ ì§€ì›í•©ë‹ˆë‹¤)"
            )

        # ì „ì—­ ë©”íƒ€ ì •ë³´
        self.symbol_to_id = data.get("symbol_to_id", {})
        self.rel_categories = data.get("rel_categories", {})
        self.num_classes = data.get("num_classes", None)

        self.images_root = images_root
        self.feature_extractor = feature_extractor
        self.transforms = transforms

    # ----------------------------------------------------
    # ğŸ”¥ ì´ë¯¸ì§€ ê²½ë¡œ ìë™ í•´ê²°: í™•ì¥ì / ê²½ë¡œ ìœ ì—° ì²˜ë¦¬
    # ----------------------------------------------------
    def _resolve_image_path(self, filename_field: str) -> str:
        """
        JSONì˜ filename í•„ë“œë¥¼ ì´ìš©í•´ ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œë¥¼ ì°¾ëŠ”ë‹¤.

        1) images_root/ + filename_field ê·¸ëŒ€ë¡œ ì‹œë„
        2) ì•ˆ ë˜ë©´ base nameë§Œ ë½‘ì•„ì„œ
           base + [.png, .jpg, .jpeg, .bmp] ìˆœì„œë¡œ íƒìƒ‰
        """
        # 1) ê·¸ëŒ€ë¡œ ì‹œë„
        direct_path = os.path.join(self.images_root, filename_field)
        if os.path.exists(direct_path):
            return direct_path

        # 2) base name + ë‹¤ì–‘í•œ í™•ì¥ì
        base = os.path.basename(filename_field)
        base_no_ext = os.path.splitext(base)[0]

        candidate_exts = [".png", ".jpg", ".jpeg", ".bmp"]
        tried_paths = [direct_path]

        for ext in candidate_exts:
            cand = os.path.join(self.images_root, base_no_ext + ext)
            tried_paths.append(cand)
            if os.path.exists(cand):
                return cand

        raise FileNotFoundError(
            "[FormulaGraphDataset] ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
            f"  filename_field = '{filename_field}'\n"
            f"  images_root    = '{self.images_root}'\n"
            "  ì‹œë„í•œ ê²½ë¡œë“¤:\n    - "
            + "\n    - ".join(tried_paths)
        )

    def __len__(self) -> int:
        return len(self.ids)

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, Dict[str, Any]]:
        # -------------------------
        # 0. í˜„ì¬ ìƒ˜í”Œ ginfo ê°€ì ¸ì˜¤ê¸°
        # -------------------------
        if self.mode == "dict":
            gid = self.ids[idx]
            ginfo = self.graphs[gid]
        else:  # "list"
            gid = idx
            ginfo = self.samples[idx]

        # -------------------------
        # 1. ì´ë¯¸ì§€ ë¡œë“œ
        # -------------------------
        if "filename" not in ginfo:
            raise KeyError(
                f"Sample {gid} ì— 'filename' í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤. "
                f"JSON ìƒì„± ì‹œ filenameì„ ê¼­ ë„£ì–´ì¤˜ì•¼ í•©ë‹ˆë‹¤."
            )

        img_path = self._resolve_image_path(ginfo["filename"])
        image = Image.open(img_path).convert("RGB")
        w, h = image.size

        # -------------------------
        # 2. GT boxes / labels / relations
        # -------------------------
        # boxes / bboxes ë‘˜ ë‹¤ ì§€ì›
        if "boxes" in ginfo:
            boxes_data = ginfo["boxes"]
        elif "bboxes" in ginfo:
            boxes_data = ginfo["bboxes"]
        else:
            raise KeyError(
                f"Sample {gid} ì— 'boxes' ë˜ëŠ” 'bboxes' í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤.\n"
                f"â†’ í•™ìŠµìš© JSONì—ëŠ” ë°˜ë“œì‹œ bbox ì •ë³´ê°€ ë“¤ì–´ê°€ì•¼ í•©ë‹ˆë‹¤."
            )

        if "labels" not in ginfo:
            raise KeyError(
                f"Sample {gid} ì— 'labels' í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤.\n"
                f"â†’ ê° ì‹¬ë³¼ì˜ class id ë¦¬ìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            )

        boxes = torch.as_tensor(boxes_data, dtype=torch.float32)      # [N,4]
        labels = torch.as_tensor(ginfo["labels"], dtype=torch.int64)  # [N]

        rel_list = ginfo.get("relations", [])
        if rel_list is None:
            rel_list = []
        relations = torch.as_tensor(rel_list, dtype=torch.int64)      # [M,3] ë˜ëŠ” [0,3]

        target: Dict[str, Any] = {
            "boxes": boxes,
            "labels": labels,
            "relations": relations,
            "image_id": torch.tensor([idx], dtype=torch.int64),
            "orig_size": torch.tensor([h, w], dtype=torch.int64),
        }

        if "latex" in ginfo:
            target["latex"] = ginfo["latex"]

        # -------------------------
        # 3. transforms (augmentation)
        # -------------------------
        if self.transforms is not None:
            image, target = self.transforms(image, target)

        # -------------------------
        # 4. feature_extractor (DETR/EGTR ì „ì²˜ë¦¬)
        # -------------------------
        if self.feature_extractor is not None:
            encoded = self.feature_extractor(
                images=image,
                return_tensors="pt",
            )
            # encoded["pixel_values"]: [1, C, H, W]
            pixel_values = encoded["pixel_values"].squeeze(0)
        else:
            # feature_extractorë¥¼ ì•ˆ ì“°ëŠ” ê²½ìš°: ì§ì ‘ ToTensor
            arr = np.array(image).astype("float32") / 255.0  # [H,W,C]
            arr = arr.transpose(2, 0, 1)                     # [C,H,W]
            pixel_values = torch.from_numpy(arr)

        return pixel_values, target
